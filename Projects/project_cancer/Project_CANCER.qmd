---
title: "Project tasks: Cancer"
author: 
  - name: "dr.sc. Paula Štancl"
    affiliation: "Kuzman Consulting d.o.o"
  - name: "dr.sc. Andrea Gelemanović"
    affiliation: "MedILS, UNIST"
format:
  html:
    self-contained: true
    toc: true
    toc-depth: 5
    code-fold: false
    fig-align: center
    df-print: paged
    code-summary: "Show code"
    code-line-numbers: false
    code-tools: true
execute:
  eval: true
  echo: true
  warning: false
  message: false
---

# Lung cancer dataset

This synthetic dataset offers comprehensive information on lung cancer patients, including demographics, medical background, treatment details, and survival data. While the data is artificially generated, it reflects patterns commonly seen in real clinical cases. It can be used for developing predictive models, analyzing patient outcomes, evaluating treatment effectiveness, and supporting various types of lung cancer research.

This dataset was sourced from [Kaggle](https://www.kaggle.com/datasets/rashadrmammadov/lung-cancer-prediction/data) and subsetted for this analysis. Kaggle is an online platform for data science and machine learning where users can find datasets, enter competitions, and share code through cloud-based notebooks. It also offers free courses and a community forum, making it a great place to learn, practice, and collaborate on real-world data problems.

## Organize your Rproject

Create a new project where you will save all the data, scripts and outputs for this Hackaton. Afterwards download the dataset:

-   [Download the dataset](lung_cancer_subset_data.csv)

Import your downloaded data into R using `fread()`

```{r, eval=FALSE}
(cancer <- data.table::fread("lung_cancer_subset_data.csv"))
```

## Exploratory analysis

a)  Use the functions `str()` and `summary()` to explore the dataset and understand what it contains.

b)  How many female and male lung cancer patients are in the dataset? Visualize the results.

```{r}
# table
cancer[,.N, cancer]
## plot
ggplot(cancer, aes(x=Gender, fill=Gender)) +
  geom_bar() +
  theme_bw() + 
stat_count(geom = "text", 
           colour = "white", size = 3.5,
           aes(label = ..count..),position=position_stack(vjust=0.5)
           )
```

c)  Are males more likely to be smokers than females? Visualize this relationship and perform the appropriate statistical test.

```{r}
table_sex_smoking <- table(cancer[, Smoking_History],
           cancer[, Gender])

##
table_sex_smoking
## test
chisq.test(table_sex_smoking)

## plot
ggplot(cancer, aes(x=Gender, fill=Smoking_History)) +
  geom_bar(position="fill") +
  theme_bw()
```

d)  Do smokers have lower number of white blood cells (column `White_Blood_Cell_Count`)? Investigate this using both visualization and statistical testing.

```{r}
## evaluate normality
ggqqplot(cancer, x = "White_Blood_Cell_Count",
         color = "Smoking_History",
         facet.by = "Smoking_History") +
  theme(legend.position = "right")

## plot
ggplot(cancer, aes(x=Smoking_History,
                   y=White_Blood_Cell_Count)) +
  geom_violin() +
  geom_boxplot() +
  theme_bw() +
  ggpubr::stat_compare_means(  )
```

e)  Visualize the distribution of `Tumor_Size_mm` per cancer `Stage`. Perform the appropriate test to determine if there is a significant difference.

```{r}
ggplot(cancer, aes(x=Tumor_Size_mm, fill=Stage)) +
  geom_density(alpha=0.4) +
  theme_bw()
```

f)  Which numerical variables are most strongly correlated?

```{r}
cor_data <- cancer[, .SD,.SDcols=is.numeric]
cor_matrix <- cor(cor_data)

png("Corr_plot.png", width = 800, height = 800)
corrplot(cor_matrix, method = 'square', type = 'upper', diag = FALSE, tl.col = "black")
dev.off()

```

## Prediction of *`Stage`* for lung cancer patients

### Feature selection

a)  Set the seed to **12**. Are there any columns that should be excluded from the dataset before modeling? Remove them!

```{r}
set.seed(12)
cancer_clean <- cancer[,-c("Patient_ID")][Stage%in%c("Stage I", "Stage IV")]
#


cancer_clean[, Stage := ifelse(Stage == "Stage I", "Low", "High")]

cancer_clean[, Stage := factor(Stage)]
```

b)  Split your data into training and test sets. Consider whether there is anything important to keep in mind when splitting the data - for example, potential data leakage or class imbalance.

```{r}

# Splitting data into training and testing sets
trainIndex <- createDataPartition(cancer_clean$Stage, 
                                  p = 0.7, 
                                  list = FALSE, 
                                  times = 1)
trainData <- cancer_clean[trainIndex, ]
testData <- cancer_clean[-trainIndex, ]

# Print the number of rows in training and testing sets
print(nrow(trainData))
```

c)  Use **forward selection** to identify and select up to 10 of the most relevant features for predicting the `Stage` of the samples.

```{r}
full_model <- glm(Stage ~ ., 
                  data = trainData, 
                  family = binomial)

# Perform forward selection & select variables
step_model_for <- stepAIC(full_model, 
                          direction = "forward",
                          trace = FALSE)
selected_vars_for <- names(coef(step_model_for))[-1]
selected_vars_for


# Run Boruta
model_boruta <- Boruta(Stage ~ ., 
                       data = trainData)
print(model_boruta)
```

### Unsupervised clustering with top 10 most significant features

a)  Perform **k-means clustering** on the full dataset (before splitting the data) using the all and top 10 most significant features.

```{r}
# Remove non-numeric columns (e.g., outcome variable)
numeric_data <- cancer_clean[, .SD, .SDcols = is.numeric]

# Standardize
scaled_all <- scale(numeric_data)

# Perform k-means on all features
set.seed(123)

# Elbow method 
fviz_nbclust(scaled_all, 
             kmeans, 
             method = "wss")


km_all <- kmeans(scaled_all, centers = 2)

# Combine K-means and original label
kmeans_df <- cbind(cancer_clean, 
                   cluster = as.factor(km_all$cluster)
                   )

# How well did k-means clustering do in comparison with known groups?
table(kmeans_df$cluster, kmeans_df$Stage)

```

b)  Visualize the dataset using **PCA** on the full dataset (before splitting the data) using all and the top 10 most significant features .

```{r}
### pca
# Visualize PCA with cluster assignment
# Perform PCA on the scaled matrix
pca_all <- prcomp(scaled_all)

# Visualize individuals, colored by cluster
fviz_pca_ind(pca_all, 
             geom.ind = "point", 
             col.ind = as.factor(km_all$cluster),  # km_all is from kmeans()
             palette = "jco",
             addEllipses = TRUE,
             legend.title = "Cluster")

# Combine PCA and original label
pca_df <- data.frame(pca_all$x, 
                     Stage = cancer_clean$Stage,
                     kmeans_res = as.factor(km_all$cluster))

# Plot PC1 vs PC2 and color by diagnosis
ggplot(pca_df, aes(PC1, PC2, col = Stage, shape=kmeans_res)) +
  geom_point(size = 2, alpha = 0.7) +
  theme_minimal() +
  labs(title = "", color = "Stage")

```

### Model development with top 10 most significant features

Develop a model using the top 10 most significant features. You can choose one of the following approaches, all using 10-fold cross-validation:

1.  **Random forest**
2.  **Logistic regression**
3.  **Bagging**

```{r}
ctrl <- trainControl(method = "cv",
                     number = 10)
```

Each group member may select a different model, or you can all use the same one.

-   Train the chosen model on the **training dataset**.

```{r}
model <- train(Stage ~ ., 
               data = trainData, 
               method = "rf",       # or "rf", or "treebag"
               trControl = ctrl,
               family = binomial)
```

-   What is the model's accuracy on the training data?

```{r}
### confusion matrix and error
table(predict(model, trainData), trainData$Stage) %>% 
  confusionMatrix()

```

-   Plot the ROC curve and report the AUC for the test set.

```{r}

library(pROC)

# Get predicted probabilities for the positive class (e.g. "Yes")
train_probs <- predict(model, newdata = trainData, type = "prob")[, "High"]
train_labels <- trainData$Stage

# Compute ROC
roc_train <- roc(train_labels, train_probs)

# Plot ROC
plot(roc_train, col = "blue", lwd = 2, main = "ROC Curve - Training")
text(0.6, 0.2, paste("AUC =", round(auc(roc_train), 3)), col = "black")

```

Now evaluate the model on the **test dataset**.

-   What is the accuracy on the test set?

```{r}
# Predicted probabilities and classes
table(predict(model, testData), testData$Stage) %>% confusionMatrix()
```

-   Plot the ROC curve and report the AUC for the test set.

```{r}
# Predict probabilities for test data
test_probs <- predict(model, newdata = testData, type = "prob")[, "High"]
test_labels <- testData$Stage

# Compute ROC
roc_test <- roc(test_labels, test_probs)

# Plot ROC
plot(roc_test, col = "darkgreen", lwd = 2, main = "ROC Curve - Test Set")
text(0.6, 0.2, paste("AUC =", round(auc(roc_test), 3)), col = "black")

```

#### What is your overall conclusion?
